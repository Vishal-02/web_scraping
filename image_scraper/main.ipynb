{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ol' fasioned way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selectolax.parser import HTMLParser\n",
    "from httpx import get\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tags(query=\"books\"):\n",
    "    url = f\"https://unsplash.com/s/photos/{query}\"\n",
    "    resp = get(url)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(\"Error getting respose\")\n",
    "    \n",
    "    tree = HTMLParser(resp.text)\n",
    "    imgs = tree.css(\"figure a img\")\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(url, keywords):\n",
    "    return not any(x in url for x in keywords)\n",
    "\n",
    "def get_hi_res(urls):\n",
    "    # remove all the premium and profile links\n",
    "    urls = [i for i in urls if img_filter(i, ['premium', 'plus', 'profile', 'placeholder'])]\n",
    "\n",
    "    # now get the link which has the hi res image\n",
    "    for _, url in enumerate(urls):\n",
    "        urls[_] = url.split(',')[-1].split(' ')[1].split('?')[0]\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(img_urls, dest=\"images\", tag=\"\"):\n",
    "    for _, url in enumerate(img_urls):\n",
    "        resp = get(url)\n",
    "        file_name = f\"{tag}_{_}\"\n",
    "        \n",
    "        if not os.path.exists(dest):\n",
    "            os.makedirs(dest)\n",
    "        \n",
    "        with open(f\"{dest}/{file_name}.jpeg\", \"wb\") as f:\n",
    "            f.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nodes = get_img_tags()\n",
    "img_urls = [i.attrs[\"srcset\"] for i in img_nodes]\n",
    "relevant_urls = get_hi_res(img_urls)\n",
    "\n",
    "save_images(relevant_urls[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
